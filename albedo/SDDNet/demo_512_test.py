import torch
import torchvision
from networks.sddnet import SDDNet
from PIL import Image
import numpy as np
from torchvision import transforms
import os
import torch.nn.functional as F

def process_demo_with_512_model():
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # ä½¿ç”¨ckptç›®å½•ä¸­çš„512x512æ¨¡å‹
    ckpt_path = './ckpt/ep_019.ckpt'
    demo_dir = './demo'
    save_dir = './demo_results_512'
    os.makedirs(save_dir, exist_ok=True)

    # åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨512x512çš„é…ç½®
    model = SDDNet(backbone='efficientnet-b3',
                   proj_planes=16,
                   pred_planes=32,
                   use_pretrained=False,
                   fix_backbone=False,
                   has_se=False,
                   dropout_2d=0,
                   normalize=True,  # æ¨¡å‹å†…éƒ¨normalize
                   mu_init=0.4,
                   reweight_mode='manual')

    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    try:
        ckpt = torch.load(ckpt_path, map_location=device)
        print(f"Checkpoint keys: {list(ckpt.keys())}")
        
        # æ£€æŸ¥checkpointå†…å®¹
        if 'model' in ckpt:
            model.load_state_dict(ckpt['model'])
        else:
            # å¦‚æœç›´æ¥æ˜¯state_dict
            model.load_state_dict(ckpt)
            
        print(f"Successfully loaded 512x512 model from {ckpt_path}")
        
        # æ‰“å°ä¸€äº›checkpointä¿¡æ¯
        if 'epoch' in ckpt:
            print(f"Epoch: {ckpt['epoch']}")
        if 'best_ber' in ckpt:
            print(f"Best BER: {ckpt['best_ber']}")
            
    except Exception as e:
        print(f"Error loading checkpoint: {e}")
        print("Let me try different loading methods...")
        
        # å°è¯•å…¶ä»–åŠ è½½æ–¹å¼
        try:
            ckpt = torch.load(ckpt_path, map_location=device)
            # å¦‚æœæœ‰ä¸åŒ¹é…çš„keysï¼Œå°è¯•strict=False
            model.load_state_dict(ckpt['model'], strict=False)
            print("Loaded with strict=False")
        except:
            return

    model.to(device)
    model.eval()

    # å›¾åƒé¢„å¤„ç† - å°è¯•ä¸¤ç§æ–¹å¼
    preprocess_configs = [
        {
            'name': 'no_norm',
            'transform': transforms.Compose([
                transforms.Resize((512, 512)),
                transforms.ToTensor()
            ])
        },
        {
            'name': 'with_norm', 
            'transform': transforms.Compose([
                transforms.Resize((512, 512)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        }
    ]

    # å¤„ç†demoç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡
    img_files = [f for f in os.listdir(demo_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not img_files:
        print("No image files found in demo directory!")
        return

    print(f"Processing {len(img_files)} image(s) with 512x512 model...")

    with torch.no_grad():
        for img_file in img_files:
            print(f"\nProcessing {img_file}...")
            
            # è¯»å–å›¾åƒ
            img_path = os.path.join(demo_dir, img_file)
            image = Image.open(img_path).convert('RGB')
            original_size = image.size
            print(f"Original image size: {original_size}")
            
            base_name = os.path.splitext(img_file)[0]
            
            for config in preprocess_configs:
                print(f"  Testing with {config['name']} preprocessing...")
                
                # é¢„å¤„ç†
                img_tensor = config['transform'](image).unsqueeze(0).to(device)
                
                # æ¨ç†
                result = model(img_tensor)
                
                # è·å–shadow mask
                shadow_logits = result['logit']
                shadow_mask = torch.sigmoid(shadow_logits).cpu()
                
                # è°ƒæ•´å›åŸå§‹å°ºå¯¸
                shadow_mask_resized = F.interpolate(shadow_mask, size=original_size[::-1], 
                                                  mode='bilinear', align_corners=False)
                
                # åº”ç”¨é˜ˆå€¼å¾—åˆ°äºŒå€¼mask
                binary_mask = (shadow_mask_resized > 0.5).float()
                
                # å‡†å¤‡å¯è§†åŒ–
                original_tensor = transforms.ToTensor()(image)
                
                # åˆ›å»ºä¸åŒçš„å¯è§†åŒ–ç‰ˆæœ¬
                soft_mask_3ch = shadow_mask_resized[0].repeat(3, 1, 1)
                binary_mask_3ch = binary_mask[0].repeat(3, 1, 1)
                
                # åˆ›å»ºå åŠ æ•ˆæœ
                overlay = original_tensor.clone()
                mask_2d = binary_mask[0][0]
                alpha = 0.6
                overlay[0] = torch.where(mask_2d > 0.5, 
                                       alpha * torch.tensor(1.0) + (1-alpha) * original_tensor[0], 
                                       original_tensor[0])
                overlay[1] = torch.where(mask_2d > 0.5, 
                                       (1-alpha) * original_tensor[1], 
                                       original_tensor[1])
                overlay[2] = torch.where(mask_2d > 0.5, 
                                       (1-alpha) * original_tensor[2], 
                                       original_tensor[2])
                
                # ä¿å­˜ç»“æœ
                comparison_path = os.path.join(save_dir, f"{base_name}_512_{config['name']}_comparison.png")
                torchvision.utils.save_image([original_tensor, soft_mask_3ch, binary_mask_3ch, overlay], 
                                           comparison_path, nrow=4, padding=2)
                
                # å•ç‹¬ä¿å­˜mask
                mask_path = os.path.join(save_dir, f"{base_name}_512_{config['name']}_mask.png") 
                torchvision.utils.save_image(binary_mask[0], mask_path)
                
                # ç»Ÿè®¡ä¿¡æ¯
                mask_ratio = torch.sum(binary_mask).item() / binary_mask.numel()
                print(f"    Shadow area ratio: {mask_ratio:.1%}")
                print(f"    Results saved: {comparison_path}")

    print("\nâœ… 512x512 model processing completed!")
    print(f"ğŸ“ Results saved in: {save_dir}")
    print("ğŸ“‹ Compare the results from different preprocessing methods to see which works best.")

if __name__ == "__main__":
    process_demo_with_512_model()
